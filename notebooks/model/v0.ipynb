{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install jaxtyping equinox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkpq1r4rdivB",
        "outputId": "15cfd03c-5f5f-4f1e-fdfe-ac5d5ad3a122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.23)\n",
            "Requirement already satisfied: equinox in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (1.23.5)\n",
            "Requirement already satisfied: typeguard<3,>=2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (2.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (4.5.0)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from equinox) (0.4.16)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->equinox) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->equinox) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->equinox) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B14rv-ZCdOVZ"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax  # https://github.com/deepmind/optax\n",
        "import torch  # https://pytorch.org\n",
        "import torchvision  # https://pytorch.org\n",
        "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping\n",
        "\n",
        "import equinox as eqx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 3e-4\n",
        "STEPS = 300\n",
        "PRINT_EVERY = 30\n",
        "SEED = 5678\n",
        "\n",
        "key = jax.random.PRNGKey(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1TF8daVdsLA",
        "outputId": "e1771765-d4d8-49f0-c9ea-69c40bc30d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalise_data = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
        "    ]\n",
        ")\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    \"MNIST\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=normalise_data,\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    \"MNIST\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=normalise_data,\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "SxZXYiZFd1fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data  = [(x.numpy()[0], y) for x, y in iter(train_dataset)]\n",
        "df    = pd.DataFrame(data, columns=['features', 'labels'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4GFhtlxufqAO",
        "outputId": "89413f0d-5e63-4562-cdfc-2206a189e221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                features  labels\n",
              "0      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       5\n",
              "1      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       0\n",
              "2      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       4\n",
              "3      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       1\n",
              "4      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       9\n",
              "...                                                  ...     ...\n",
              "59995  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       8\n",
              "59996  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       3\n",
              "59997  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       5\n",
              "59998  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       6\n",
              "59999  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...       8\n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bdc49aa-4d54-4a28-bca3-a512145dddd5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bdc49aa-4d54-4a28-bca3-a512145dddd5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8bdc49aa-4d54-4a28-bca3-a512145dddd5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8bdc49aa-4d54-4a28-bca3-a512145dddd5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8cfa47f0-dee1-4dbb-8d91-34d0da57c894\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cfa47f0-dee1-4dbb-8d91-34d0da57c894')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8cfa47f0-dee1-4dbb-8d91-34d0da57c894 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['features'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaqR7_4cf1ue",
        "outputId": "f93e88b7-6e8d-46c4-eef3-d095179d5cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -0.9764706 , -0.85882354, -0.85882354,\n",
              "        -0.85882354, -0.01176471,  0.06666672,  0.37254906, -0.79607844,\n",
              "         0.30196083,  1.        ,  0.9372549 , -0.00392157, -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -0.7647059 , -0.7176471 ,\n",
              "        -0.26274508,  0.20784318,  0.33333337,  0.9843137 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.7647059 ,  0.34901965,\n",
              "         0.9843137 ,  0.8980392 ,  0.5294118 , -0.4980392 , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -0.6156863 ,  0.8666667 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9843137 ,  0.96862745, -0.27058822, -0.35686272,\n",
              "        -0.35686272, -0.56078434, -0.69411767, -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -0.85882354,  0.7176471 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5529412 ,\n",
              "         0.427451  ,  0.9372549 ,  0.8901961 , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -0.372549  ,  0.22352946,\n",
              "        -0.1607843 ,  0.9843137 ,  0.9843137 ,  0.60784316, -0.9137255 ,\n",
              "        -1.        , -0.6627451 ,  0.20784318, -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -0.8901961 ,\n",
              "        -0.99215686,  0.20784318,  0.9843137 , -0.29411763, -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        ,  0.09019613,  0.9843137 ,  0.4901961 , -0.9843137 ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -0.9137255 ,  0.4901961 ,  0.9843137 , -0.45098037,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -0.7254902 ,  0.8901961 ,  0.7647059 ,\n",
              "         0.254902  , -0.15294117, -0.99215686, -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -0.36470586,  0.88235295,\n",
              "         0.9843137 ,  0.9843137 , -0.06666666, -0.8039216 , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -0.64705884,\n",
              "         0.45882356,  0.9843137 ,  0.9843137 ,  0.17647064, -0.7882353 ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -0.8745098 , -0.27058822,  0.9764706 ,  0.9843137 ,  0.4666667 ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        ,  0.9529412 ,  0.9843137 ,  0.9529412 ,\n",
              "        -0.4980392 , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -0.6392157 ,\n",
              "         0.0196079 ,  0.43529415,  0.9843137 ,  0.9843137 ,  0.62352943,\n",
              "        -0.9843137 , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -0.69411767,  0.16078436,  0.79607844,\n",
              "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9607843 ,  0.427451  ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -0.8117647 , -0.10588235,  0.73333335,  0.9843137 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9843137 ,  0.5764706 , -0.38823527, -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -0.81960785, -0.4823529 ,\n",
              "         0.67058825,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
              "         0.5529412 , -0.36470586, -0.9843137 , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -0.85882354,  0.3411765 ,  0.7176471 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5294118 , -0.372549  ,\n",
              "        -0.92941177, -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -0.5686275 ,\n",
              "         0.34901965,  0.77254903,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
              "         0.9843137 ,  0.9137255 ,  0.04313731, -0.9137255 , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        ,  0.06666672,\n",
              "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.6627451 ,  0.05882359,\n",
              "         0.03529418, -0.8745098 , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ],\n",
              "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
              "        -1.        , -1.        , -1.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "df['labels'].plot(kind='hist', bins=20, title='labels')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "99-T5jq1iT69",
        "outputId": "1335b582-512b-4f22-f2e5-c35ea594a1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking our data a bit (by now, everyone knows what the MNIST dataset looks like)\n",
        "dummy_x, dummy_y = next(iter(trainloader))\n",
        "dummy_x = dummy_x.numpy()\n",
        "dummy_y = dummy_y.numpy()\n",
        "print(dummy_x.shape)  # 64x1x28x28\n",
        "print(dummy_y.shape)  # 64\n",
        "print(dummy_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSwW1eA_gjgF",
        "outputId": "3e9ee9e5-ef80-43fa-f7ea-5b304d0d2692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1, 28, 28)\n",
            "(64,)\n",
            "[0 2 2 4 5 4 1 0 5 5 2 3 8 1 3 0 5 5 1 2 1 7 6 5 6 1 4 3 1 9 8 3 9 8 3 6 6\n",
            " 8 2 3 3 3 5 4 5 4 1 5 5 4 8 4 7 8 2 6 7 8 0 9 0 3 1 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(eqx.Module):\n",
        "    layers: list\n",
        "\n",
        "    def __init__(self, key):\n",
        "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
        "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
        "        # with a small MLP on top.\n",
        "        self.layers = [\n",
        "            eqx.nn.Conv2d(1, 3, kernel_size=4, key=key1),\n",
        "            eqx.nn.MaxPool2d(kernel_size=2),\n",
        "            jax.nn.relu,\n",
        "            jnp.ravel,\n",
        "            eqx.nn.Linear(1728, 512, key=key2),\n",
        "            jax.nn.sigmoid,\n",
        "            eqx.nn.Linear(512, 64, key=key3),\n",
        "            jax.nn.relu,\n",
        "            eqx.nn.Linear(64, 10, key=key4),\n",
        "            jax.nn.log_softmax,\n",
        "        ]\n",
        "\n",
        "    def __call__(self, x: Float[Array, \"1 32 32\"]) -> Float[Array, \"10\"]:\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "key, subkey = jax.random.split(key, 2)\n",
        "model = CNN(subkey)"
      ],
      "metadata": {
        "id": "yTy-9s_pigYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZVeiF40mY8l",
        "outputId": "3154b1e5-82ec-4ef9-8339-dbc0d8694d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  layers=[\n",
            "    Conv2d(\n",
            "      num_spatial_dims=2,\n",
            "      weight=f32[3,1,4,4],\n",
            "      bias=f32[3,1,1],\n",
            "      in_channels=1,\n",
            "      out_channels=3,\n",
            "      kernel_size=(4, 4),\n",
            "      stride=(1, 1),\n",
            "      padding=((0, 0), (0, 0)),\n",
            "      dilation=(1, 1),\n",
            "      groups=1,\n",
            "      use_bias=True\n",
            "    ),\n",
            "    MaxPool2d(\n",
            "      init=-inf,\n",
            "      operation=<function max>,\n",
            "      num_spatial_dims=2,\n",
            "      kernel_size=(2, 2),\n",
            "      stride=(1, 1),\n",
            "      padding=((0, 0), (0, 0)),\n",
            "      use_ceil=False\n",
            "    ),\n",
            "    <wrapped function relu>,\n",
            "    <wrapped function ravel>,\n",
            "    Linear(\n",
            "      weight=f32[512,1728],\n",
            "      bias=f32[512],\n",
            "      in_features=1728,\n",
            "      out_features=512,\n",
            "      use_bias=True\n",
            "    ),\n",
            "    <wrapped function sigmoid>,\n",
            "    Linear(\n",
            "      weight=f32[64,512],\n",
            "      bias=f32[64],\n",
            "      in_features=512,\n",
            "      out_features=64,\n",
            "      use_bias=True\n",
            "    ),\n",
            "    <wrapped function relu>,\n",
            "    Linear(\n",
            "      weight=f32[10,64],\n",
            "      bias=f32[10],\n",
            "      in_features=64,\n",
            "      out_features=10,\n",
            "      use_bias=True\n",
            "    ),\n",
            "    <wrapped function log_softmax>\n",
            "  ]\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(\n",
        "    model: CNN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
        ") -> Float[Array, \"\"]:\n",
        "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
        "    # a single input input image of shape (1, 28, 28).\n",
        "    #\n",
        "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
        "    # leading (batch) axis.\n",
        "    pred_y = jax.vmap(model)(x)\n",
        "    return cross_entropy(y, pred_y)\n",
        "\n",
        "\n",
        "def cross_entropy(\n",
        "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
        ") -> Float[Array, \"\"]:\n",
        "    # y are the true targets, and should be integers 0-9.\n",
        "    # pred_y are the log-softmax'd predictions.\n",
        "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
        "    return -jnp.mean(pred_y)\n",
        "\n",
        "\n",
        "# Example loss\n",
        "loss_value = loss(model, dummy_x, dummy_y)\n",
        "print(loss_value.shape)  # scalar loss\n",
        "# Example inference\n",
        "output = jax.vmap(model)(dummy_x)\n",
        "print(output.shape)  # batch of predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmje2zH6mtiB",
        "outputId": "0e613022-f92f-40a2-8cd0-7f1f66f351ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n",
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will work!\n",
        "params, static = eqx.partition(model, eqx.is_array)\n",
        "\n",
        "\n",
        "def loss2(params, static, x, y):\n",
        "    model = eqx.combine(params, static)\n",
        "    return loss(model, x, y)\n",
        "\n",
        "\n",
        "loss_value, grads = jax.value_and_grad(loss2)(params, static, dummy_x, dummy_y)\n",
        "print(loss_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7xDGYqlsIIe",
        "outputId": "a76ea300-bfbe-41e0-e1a2-5c844bbc8f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.285676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an error!\n",
        "jax.value_and_grad(loss)(model, dummy_x, dummy_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "42vDQfUZvDJG",
        "outputId": "ed6a4acb-a2d2-4e09-a7a1-f781e91fa48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-334a3495e950>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This is an error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcheck_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_jaxtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     raise TypeError(f\"Argument '{arg}' of type {type(arg)} is not a valid \"\n\u001b[0m\u001b[1;32m    357\u001b[0m                     \"JAX type.\")\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Argument '<function max at 0x78d702e28790>' of type <class 'function'> is not a valid JAX type."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will work too!\n",
        "value, grads = eqx.filter_value_and_grad(loss)(model, dummy_x, dummy_y)\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqwj9zQbvMdy",
        "outputId": "99401aeb-c74e-47de-f2fc-9b3cfe24bbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.285676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = eqx.filter_jit(loss)  # JIT our loss function from earlier!\n",
        "\n",
        "\n",
        "@eqx.filter_jit\n",
        "def compute_accuracy(\n",
        "    model: CNN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
        ") -> Float[Array, \"\"]:\n",
        "    \"\"\"This function takes as input the current model\n",
        "    and computes the average accuracy on a batch.\n",
        "    \"\"\"\n",
        "    pred_y = jax.vmap(model)(x)\n",
        "    pred_y = jnp.argmax(pred_y, axis=1)\n",
        "    return jnp.mean(y == pred_y)"
      ],
      "metadata": {
        "id": "btAxYl0UvSVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model: CNN, testloader: torch.utils.data.DataLoader):\n",
        "    \"\"\"This function evaluates the model on the test dataset,\n",
        "    computing both the average loss and the average accuracy.\n",
        "    \"\"\"\n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    for x, y in testloader:\n",
        "        x = x.numpy()\n",
        "        y = y.numpy()\n",
        "        # Note that all the JAX operations happen inside `loss` and `compute_accuracy`,\n",
        "        # and both have JIT wrappers, so this is fast.\n",
        "        avg_loss += loss(model, x, y)\n",
        "        avg_acc += compute_accuracy(model, x, y)\n",
        "    return avg_loss / len(testloader), avg_acc / len(testloader)"
      ],
      "metadata": {
        "id": "jyFUYQk2vUBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l3GUiRWvVru",
        "outputId": "0e095b46-d3fc-42de-ca28-8fa610c76120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array(2.3078082, dtype=float32), Array(0.10081609, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim = optax.adamw(LEARNING_RATE)"
      ],
      "metadata": {
        "id": "mkftuLSZvXfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model: CNN,\n",
        "    trainloader: torch.utils.data.DataLoader,\n",
        "    testloader: torch.utils.data.DataLoader,\n",
        "    optim: optax.GradientTransformation,\n",
        "    steps: int,\n",
        "    print_every: int,\n",
        ") -> CNN:\n",
        "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
        "    # so filter out everything else.\n",
        "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
        "\n",
        "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
        "    # the model -- into a single JIT region. This ensures things run as fast as\n",
        "    # possible.\n",
        "    @eqx.filter_jit\n",
        "    def make_step(\n",
        "        model: CNN,\n",
        "        opt_state: PyTree,\n",
        "        x: Float[Array, \"batch 1 28 28\"],\n",
        "        y: Int[Array, \" batch\"],\n",
        "    ):\n",
        "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
        "        updates, opt_state = optim.update(grads, opt_state, model)\n",
        "        model = eqx.apply_updates(model, updates)\n",
        "        return model, opt_state, loss_value\n",
        "\n",
        "    # Loop over our training dataset as many times as we need.\n",
        "    def infinite_trainloader():\n",
        "        while True:\n",
        "            yield from trainloader\n",
        "\n",
        "    for step, (x, y) in zip(range(steps), infinite_trainloader()):\n",
        "        # PyTorch dataloaders give PyTorch tensors by default,\n",
        "        # so convert them to NumPy arrays.\n",
        "        x = x.numpy()\n",
        "        y = y.numpy()\n",
        "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
        "        if (step % print_every) == 0 or (step == steps - 1):\n",
        "            test_loss, test_accuracy = evaluate(model, testloader)\n",
        "            print(\n",
        "                f\"{step=}, train_loss={train_loss.item()}, \"\n",
        "                f\"test_loss={test_loss.item()}, test_accuracy={test_accuracy.item()}\"\n",
        "            )\n",
        "    return model"
      ],
      "metadata": {
        "id": "mC-7jn8XvYz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model, trainloader, testloader, optim, STEPS, PRINT_EVERY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5LLiQItvohz",
        "outputId": "a9cc9628-e13e-4600-80f0-727083599908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step=0, train_loss=2.3139700889587402, test_loss=2.3045575618743896, test_accuracy=0.12659235298633575\n",
            "step=30, train_loss=2.1834115982055664, test_loss=2.168821334838867, test_accuracy=0.32354697585105896\n",
            "step=60, train_loss=1.9426651000976562, test_loss=1.884477972984314, test_accuracy=0.6247014403343201\n",
            "step=90, train_loss=1.5136895179748535, test_loss=1.4511332511901855, test_accuracy=0.737261176109314\n",
            "step=120, train_loss=1.0158263444900513, test_loss=1.0274163484573364, test_accuracy=0.8037420511245728\n",
            "step=150, train_loss=0.7833031415939331, test_loss=0.7509862780570984, test_accuracy=0.8215565085411072\n",
            "step=180, train_loss=0.6055166721343994, test_loss=0.5831165909767151, test_accuracy=0.8663415312767029\n",
            "step=210, train_loss=0.5323667526245117, test_loss=0.5041787028312683, test_accuracy=0.8733081221580505\n",
            "step=240, train_loss=0.4918504059314728, test_loss=0.44156938791275024, test_accuracy=0.8894307613372803\n",
            "step=270, train_loss=0.529234766960144, test_loss=0.4182316064834595, test_accuracy=0.8884354829788208\n",
            "step=299, train_loss=0.27532264590263367, test_loss=0.3809020519256592, test_accuracy=0.8981887102127075\n"
          ]
        }
      ]
    }
  ]
}